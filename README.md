# An Entirely Extracted and Secure Multi-bit Watermark for Large Language Models.

![1](https://github.com/SecureWatermarkforLLM/ESMark/tree/main/Figures/fig1.pdf)

### Datasets

Commonly used datasets in the field of natural language processing and watermarking are used to evaluate the performance of ESMark, which are the instruction following task: [AlpacaFarm](https://github.com/tatsu-lab/alpaca_farm), the question answering tasks: [ELI5](https://github.com/facebookresearch/ELI5) and [FinQA](https://sites.google.com/view/fiqa/home). You can get these datasets from [here](https://github.com/THU-KEG/WaterBench/tree/main/data/WaterBench).


### Models

The models we used are LLama2-7B-chat / ChatGLM3-6B. You can get the LLama2-7B-chat from [here](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf) and ChatGLM3-6B from [here](https://huggingface.co/THUDM/chatglm3-6b).


### Conda Environment
python 3.10

`pip install -r requirements.txt`


### **Demos**







